{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Run the top two cells in this notebook first, every time you reopen your notebook.\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nn_practice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural network practice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this problem, you'll do some calculations for a neural network with one input unit ($x_{1}$), one hidden unit ($x_{2}$), and one output unit ($x_{3}$). This network does not include any bias nodes. Here's a picture:\n",
    "\n",
    "<img src=\"images/NeuralNetChain.png\" alt=\"Neural network architecture\" style=\"width: 500px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">Assume that $g$ is a logistic function:\n",
    "\n",
    "$$g(n) = \\frac{1}{1+e^{-n}}$$\n",
    "\n",
    "If we initialize the connection weights to $w_{1} = 5$ and $w_{2} = -0.5$, then what are the activations for $x_{2}$ and $x_{3}$ when $x_{1} = 0$? What about when $x_{1} = 1$? Show your work.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### When $x_1 == 0$\n",
    "$x_2 = \\frac{1}{1+e^{w_1 \\cdot x_1}} = \\frac{1}{2}$\n",
    "\n",
    "$x_3 = \\frac{1}{1+e^{w_2 \\cdot x_2}} = 0.5621765 $\n",
    "\n",
    "#### When $x_1 == 1$\n",
    "$x_2 = \\frac{1}{1+e^{w_1 \\cdot x_1}} = 0.00669$\n",
    "\n",
    "$x_3 = \\frac{1}{1+e^{w_2 \\cdot x_2}} = 0.50083 $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">We'd like this network to learn two $(x_{1},x_{3})$ pairs: $(0,1)$ and $(1,0)$. Recall that the squared error for a single input/output pair is just the square of the difference between the network's output and the target output. For multiple input/output pairs, the total errror is calculated as the sum of squared error: the sum of each of the individual squared errors. This is known as the <i>sum squared error</i>. Compute the sum squared error for these two pairs given the $g$ and weights shown above. Show your work.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SquaredError = $(y -g(Wx))^2$\n",
    "\n",
    "for (0,1): y = 1, $g(Wx) = 0.562$, error = $0.1917$\n",
    "\n",
    "for (1,0): y = 0, $g(Wx) = 0.50083$, error = $0.25083$\n",
    "\n",
    "$\\therefore$\n",
    "\n",
    "SummedError = $0.1917 + 0.25083 = 0.44253$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">In <tt>nn_practice.py</tt>, write a function <tt>calc_output</tt> that takes two parameters: (1) a value for $x_{1}$ and (2) the weights for the network, expressed as a tuple $(w_{1}, w_{2})$. This function should return the output for the network, assuming that $g$ is the logistic function. Test your function in the cell below.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the output from w1 = 0: 0.5621765008857981\n",
      "the output from w1 = 1: 0.500836605584804\n"
     ]
    }
   ],
   "source": [
    "print(\"the output from w1 = 0:\",nn_practice.calc_output(0,(5,-0.5)))\n",
    "print(\"the output from w1 = 1:\",nn_practice.calc_output(1,(5,-0.5)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">Now write a function <tt>sum_squared_error</tt> in <tt>nn_practice.py</tt> that takes two parameters: (1) a two-dimensional list, where each inner list has two items: the value for the input, followed by the target value for the output, and (2) the weights for the network. This function should return the sum squared error for these data. Again, assume that $g$ is the logistic function. Test your function in the cell below.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">In the cell below, write code to make a plot of the sum squared error in your network on the two pairs given above as a function of the weights. You'll want to consider $(w_{1},w_{2}$ pairs where each item in the pair can range from $-5$ to $5$. These will be your x/y coordinates. Then, the color of each point in the grid will be based on the value of the sum squared error for the two pairs. The <tt>contourf</tt> function in matplotlib facilitates making such a graph.\n",
    "\n",
    "<a href=\"http://matplotlib.org/api/pyplot_api.html?highlight=contour#matplotlib.pyplot.contour\">You can see some documentation here.</a> Note that you should be carefuly about the indexing in relating the values of the weights and the values of the sum-squared error - it's easy to get the axes backwards. <a href=\"http://matplotlib.org/api/pyplot_api.html?highlight=contour#matplotlib.pyplot.colorbar\">Use the <tt>colorbar</tt> function</a> to add a legend that will allow you to interpret the meaning of the colors in your plot. Note that the input to colorbar is the object returned by contourf. Make sure to label your axes and title the graph appropriately. Based on your graph, suggest a set of weights that would do better (i.e., would have a lower sum squared error) than your initial weights of $w_1= 5$ and $w_2= âˆ’0.5$.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">Weight updates can be computed using the delta rule and the generalized delta rule. One thing you'll need to know is the derivative of the logistic function, which is: $g'(n) = g(n)\\cdot(1-g(n))$. Write a function <tt>compute_w2_update</tt> in your module that takes in the following parameters: (1) the input to the network, (2) the target (desired) output, (3) the weights as a tuple $(w_{1},w_{2})$, and (4) the learning rate $\\eta$. It should return the change that should be made to $w_{2}$ given that this input/output error was just observed. Test your function in the cell below, comparing the output to one that you calculate by hand.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">Now, write a function <tt>compute_w1_update</tt> in your module that takes in the following parameters: (1) the input to the network, (2) the target (desired) output, (3) the weights as a tuple $(w_{1},w_{2})$, and (4) the learning rate $\\eta$. It should return the change that should be made to $w_{1}$ given that this input/output error was just observed. Test your function in the cell below, comparing the output to one that you calculate by hand.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">Use your function to compute the weight updates given that you observe (1, 0) and (0,1). Do these weight updates take you in the direction of the \"optimal\" weights you identified from your plot? Explain your results in terms of your error plot and what you know about gradient descent optimization algorithms.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting neural network results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used a neural network to try to classify which parts of an image were grass versus which parts of the image were path.  (<a href=\"http://archive.ics.uci.edu/ml/datasets/Image+Segmentation\">You can learn more about the dataset here.</a>\n",
    "\n",
    "The graph below shows my sum of squared errors for various numbers of hidden units in my network. I always had 19 input units, and a single output unit, plus biases at each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEZCAYAAAB1mUk3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMwP+P8hzUkAGwSwVAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10b4a8390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "data = np.loadtxt(\"data/NetworkError.txt\")\n",
    "\n",
    "plt.plot(range(2,11), data[:,1])\n",
    "plt.xlabel(\"Number of hidden units\")\n",
    "plt.ylabel(\"Sum squared error\")\n",
    "plt.title(\"Training error as a function of network complexity\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">Using what you know about neural networks and when they do and do not learn successfully, briefly explain why I might see the pattern observed in the graph.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">In a few sentences explain what might happen if the learning rate was set too high and conceptually why this could occur.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
